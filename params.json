{"name":"Weave","tagline":"The Docker Network","body":"# Weave - the Docker network\r\n\r\nWeave creates a virtual network that connects Docker containers\r\ndeployed across multiple hosts.\r\n\r\n![Weave Virtual Network](/docs/virtual-network.png?raw=true \"Weave Virtual Network\")\r\n\r\nApplications use the network just as if the containers were all\r\nplugged into the same network switch, with no need to configure port\r\nmappings, links, etc. Services provided by application containers on\r\nthe weave network can be made accessible to the outside world,\r\nregardless of where those containers are running. Similarly, existing\r\ninternal systems can be exposed to application containers irrespective\r\nof their location.\r\n\r\n![Weave Deployment](/docs/deployment.png?raw=true \"Weave Deployment\")\r\n\r\nWeave can traverse firewalls and operate in partially connected\r\nnetworks. Traffic can be encrypted, allowing hosts to be connected\r\nacross an untrusted network.\r\n\r\nWith weave you can easily construct applications consisting of\r\nmultiple containers, running anywhere.\r\n\r\nWeave works alongside Docker's existing (single host) networking\r\ncapabilities, so these can continue to be used by containers.\r\n\r\n## Installation\r\n\r\nTo run weave on a host, you need to install...\r\n\r\n1. docker. We've tested with versions 0.9.1 through 1.2.0, but other\r\n   versions should work too.\r\n2. weave. Install this with\r\n\r\n        sudo wget -O /usr/local/bin/weave \\\r\n          https://raw.githubusercontent.com/zettio/weave/master/weaver/weave\r\n        sudo chmod a+x /usr/local/bin/weave\r\n\r\n3. (recommended) ethtool. On many systems this is installed already;\r\n   if not then grab it via your favourite package manager. On some\r\n   systems, weave application container networking may not operate\r\n   correctly unless ethtool is available.\r\n\r\n4. (optional) conntrack. Install this via your favourite package\r\n   manager. Without conntrack, the weave network may not re-establish\r\n   itself fully when individual weave instances are stopped (with\r\n   `weave stop`) and restarted quickly (typically within ~3 minutes).\r\n\r\n## Example\r\n\r\nSay you have docker running on two hosts, accessible to each other as\r\n$HOST1 and $HOST2, and want to deploy an application consisting of two\r\ncontainers, one on each host.\r\n\r\nOn $HOST1 run (as root)\r\n\r\n    host1# weave launch 10.0.0.1/16\r\n    host1# C=$(weave run 10.0.1.1/24 -t -i ubuntu)\r\n\r\nThe first line starts the weave router, in a container. This needs to\r\nbe done once on each host. We tell weave that its IP address should\r\nbe 10.0.0.1, and that the weave network is on 10.0.0.0/16.\r\n\r\nThe second line starts our application container. We give it an IP\r\naddress and network (a subnet of the weave network). `weave run`\r\ninvokes `docker run -d` with all the parameters following the IP\r\naddress and netmask. So we could be launching any container this way;\r\nhere we just take a stock ubuntu container and launch a shell in it.\r\n\r\nIf our application consists of more than one container on this host we\r\nsimply launch them with a variation on that second line.\r\n\r\nThe IP addresses and netmasks can be anything you like which doesn't\r\nconflict with any IP ranges of 'external' services the hosts or your\r\ncontainers need to connect to. The same IP range must be used\r\neverywhere, and the individual IP addresses must, of course, be\r\nunique.\r\n\r\nWe repeat similar steps on $HOST2...\r\n\r\n    host2# weave launch 10.0.0.2/16 $HOST1\r\n    host2# C=$(weave run 10.0.1.2/24 -t -i ubuntu)\r\n\r\nThe only difference, apart from the choice of IP addresses for the\r\nweave router and the application container, is that we tell our weave\r\nthat it should peer with the weave on $HOST1 (specified as the IP\r\naddress by which $HOST2 can reach it). NB: if there is a firewall\r\nbetween $HOST1 and $HOST2, you must open port 6783 for TCP and UDP.\r\n\r\nNote that we could instead have told the weave on $HOST1 to connect to\r\n$HOST2, or told both about each other. Order does not matter here;\r\nweave automatically (re)connects to peers when they become\r\navailable. Also, we can tell weave to connect to multiple peers by\r\nsupplying multiple addresses, separated by spaces. And we can\r\n[add peers dynamically](#dynamic-topologies).\r\n\r\nNow that we've got everything set up, let's see whether our containers\r\ncan talk to each other...\r\n\r\nOn $HOST1...\r\n\r\n    host1# docker attach $C\r\n    root@28841bd02eff:/# ping -c 1 -q 10.0.1.2\r\n    PING 10.0.1.2 (10.0.1.2): 48 data bytes\r\n    --- 10.0.1.2 ping statistics ---\r\n    1 packets transmitted, 1 packets received, 0% packet loss\r\n    round-trip min/avg/max/stddev = 1.048/1.048/1.048/0.000 ms\r\n\r\nSimilarly, on $HOST2...\r\n\r\n    host2# docker attach $C\r\n    root@f76829496120:/# ping -c 1 -q 10.0.1.1\r\n    PING 10.0.1.1 (10.0.1.1): 48 data bytes\r\n    --- 10.0.1.1 ping statistics ---\r\n    1 packets transmitted, 1 packets received, 0% packet loss\r\n    round-trip min/avg/max/stddev = 1.034/1.034/1.034/0.000 ms\r\n\r\nSo there we have it, two containers on separate hosts happily talking\r\nto each other.\r\n\r\n## Features\r\n\r\nWeave has a few more features beyond those illustrated by the basic\r\nexample above...\r\n\r\n### Virtual Ethernet Switch\r\n\r\nTo application containers, the network established by weave looks\r\nlike a giant Ethernet switch to which all the containers are\r\nconnected.\r\n\r\nContainers can easily access services from each other; e.g. in the\r\ncontainer on $HOST1 we can start a netcat \"service\" with\r\n\r\n    root@28841bd02eff:/# nc -lk -p 4422\r\n\r\nand then connect to it from the container on $HOST2 with\r\n\r\n    root@f76829496120:/# echo 'Hello, world.' | nc 10.0.1.1 4422\r\n\r\nNote that *any* protocol is supported. Doesn't even have to be over\r\nTCP/IP, e.g. a netcat UDP service would be run with\r\n\r\n    root@28841bd02eff:/# nc -lu -p 5533\r\n\r\n    root@f76829496120:/# echo 'Hello, world.' | nc -u 10.0.1.1 5533\r\n\r\nWe can deploy the entire arsenal of standard network tools and\r\napplications, developed over decades, to configure, secure, monitor,\r\nand troubleshoot our container network. To put it another way, we can\r\nnow re-use the same tools and techniques when deploying applications\r\nas containers as we would have done when deploying them 'on metal' in\r\nour data centre.\r\n\r\n### Application isolation\r\n\r\nA single weave network can host multiple, isolated applications, with\r\neach application's containers being able to communicate with each\r\nother but not containers of other applications.\r\n\r\nTo accomplish that, we assign each application a different subnet. So,\r\nin the above example, if we wanted to add another application similar\r\nto, but isolated from, our first, we'd launch the containers with...\r\n\r\n    host1# D=$(weave run 10.0.2.1/24 -t -i ubuntu)\r\n    host2# D=$(weave run 10.0.2.2/24 -t -i ubuntu)\r\n\r\nA quick 'ping' test in the containers confirms that they can talk to\r\neach other but not the containers of our first application...\r\n\r\n    host1# docker attach $D\r\n    \r\n    root@da50502598d5:/# ping -c 1 -q 10.0.2.2\r\n    PING 10.0.2.2 (10.0.2.2): 48 data bytes\r\n    --- 10.0.2.2 ping statistics ---\r\n    1 packets transmitted, 1 packets received, 0% packet loss\r\n    round-trip min/avg/max/stddev = 0.562/0.562/0.562/0.000 ms\r\n    \r\n    root@da50502598d5:/# ping -c 1 -q 10.0.1.1\r\n    PING 10.0.1.1 (10.0.1.1) 56(84) bytes of data.\r\n    --- 10.0.1.1 ping statistics ---\r\n    1 packets transmitted, 0 received, 100% packet loss, time 0ms\r\n    \r\n    root@da50502598d5:/# ping -c 1 -q 10.0.1.2\r\n    PING 10.0.1.2 (10.0.1.2) 56(84) bytes of data.\r\n    --- 10.0.1.2 ping statistics ---\r\n    1 packets transmitted, 0 received, 100% packet loss, time 0ms\r\n\r\nThis isolation-through-subnets scheme is an example of carrying over a\r\nwell-known technique from the 'on metal' days to containers.\r\n\r\n### Dynamic network attachment\r\n\r\nIn some scenarios containers are started independently, e.g. via some\r\nexisting tool chain, or require more complex startup sequences than\r\nprovided by `weave run`. And sometimes the decision which application\r\nnetwork a container should be part of is made post-startup. For these\r\nsituations, weave allows an existing, running container to be attached\r\nto the weave network. To illustrate, we can achieve the same effect as\r\nthe first example with\r\n\r\n    host1# C=$(docker run -d -t -i ubuntu)\r\n    host1# weave attach 10.0.1.1/24 $C\r\n\r\nThere is a matching `weave detach` command:\r\n\r\n    host1# weave detach 10.0.1.1/24 $C\r\n\r\nYou can detach a container from one application network and attach it\r\nto another:\r\n\r\n    host1# weave detach 10.0.1.1/24 $C\r\n    host1# weave attach 10.0.2.1/24 $C\r\n\r\nor attach a container to multiple application networks, effectively\r\nsharing it between applications:\r\n\r\n    host1# weave attach 10.0.1.1/24 $C\r\n    host1# weave attach 10.0.2.1/24 $C\r\n\r\n### Security\r\n\r\nIn order to connect containers across untrusted networks, weave peers\r\ncan be told to encrypt traffic by supplying a `-password` option when\r\nlaunching weave, e.g.\r\n\r\n    host1# weave launch 10.0.0.1/16 -password wEaVe\r\n\r\nThe same password must be specified for all weave peers; it is a\r\ncomponent in the creation of ephemeral session keys for connections\r\nbetween peers.\r\n\r\n### Host network integration\r\n\r\nWeave application networks can be integrated with a host's network,\r\nestablishing connectivity between the host and application containers\r\nanywhere.\r\n\r\nLet's say that in our example we want $HOST2 to have access to the\r\napplication containers. On $HOST2 we run\r\n\r\n    host2# weave expose 10.0.1.102/24\r\n\r\nchoosing an unused IP address in the application subnet. (There is a\r\ncorresponding 'hide' command to revert this step.)\r\n\r\nNow\r\n\r\n    host2# ping 10.0.1.2\r\n\r\nwill work. And, more interestingly,\r\n\r\n    host2# ping 10.0.1.1\r\n\r\nwill work too, which is talking to a container that resides on $HOST1.\r\n\r\n### Service export\r\n\r\nServices running in containers on a weave network can be made\r\naccessible to the outside world (and, more generally, other networks)\r\nfrom any weave host, irrespective of where the service containers are\r\nlocated.\r\n\r\nSay we want to make our example netcat \"service\", which is running in\r\na container on $HOST1, accessible to the outside world via $HOST2.\r\n\r\nFirst we need to expose the application network to $HOST2, as\r\nexplained [above](#host-network-integration), i.e.\r\n\r\n    host2# weave expose 10.0.1.102/24\r\n\r\nThen we add a NAT rule to route from the outside world to the\r\ndestination container service.\r\n\r\n    host2# iptables -t nat -A PREROUTING -p tcp -i eth0 --dport 2211 \\\r\n           -j DNAT --to-destination 10.0.1.1:4422\r\n\r\nHere we are assuming that the \"outside world\" is connecting to $HOST2\r\nvia 'eth0'. We want TCP traffic to port 2211 on the external IPs to be\r\nrouted to our 'nc' service, which is running on port 4422 in the\r\ncontainer with IP 10.0.1.1.\r\n\r\nWith the above in place, we can connect to our 'nc' service from\r\nanywhere with\r\n\r\n    echo 'Hello, world.' | nc $HOST2 2211\r\n\r\n(NB: due to the way routing is handled in the Linux kernel, this won't\r\nwork when run *on* $HOST2.)\r\n\r\nSimilar NAT rules to the above can used to expose services not just to\r\nthe outside world but also other, internal, networks.\r\n\r\n### Service import\r\n\r\nApplications running in containers on a weave network can be given\r\naccess to services which are only reachable from certain weave hosts,\r\nirrespective of where the application containers are located.\r\n\r\nSay that, as an extension of our example, we have a netcat service\r\nrunning on $HOST3, port 2211, and that $HOST3 is not part of the weave\r\nnetwork and is only reachable from $HOST1, not $HOST2. Nevertheless we\r\nwant to make the service accessible to an application running in a\r\ncontainer on $HOST2.\r\n\r\nFirst we need to expose the application network to the host, as\r\nexplained [above](#host-network-integration), this time on $HOST1,\r\ni.e.\r\n\r\n    host1# weave expose 10.0.1.101/24\r\n\r\nThen we add a NAT rule to route from the above IP to the destination\r\nservice.\r\n\r\n    host1# iptables -t nat -A PREROUTING -p tcp -d 10.0.1.101 --dport 3322 \\\r\n           -j DNAT --to-destination $HOST3:2211\r\n\r\nThis allows any application container to reach the service by\r\nconnecting to 10.0.1.101:3322. So if $HOST3 is indeed running a netcat\r\nservice on port 2211, e.g.\r\n\r\n    host3# nc -kl 2211\r\n\r\nthen we can connect to it from our application container on $HOST2 with\r\n\r\n    root@f76829496120:/# echo 'Hello, world.' | nc 10.0.1.101 3322\r\n\r\nThe same command will work from any application container.\r\n\r\n### Service binding\r\n\r\nImporting a service provides a degree of indirection that allows late\r\nand dynamic binding, similar to what can be achieved with a proxy. In\r\nour example, application containers are unaware that the service they\r\nare accessing at `10.0.1.101:3322` is in fact residing on\r\n`$HOST3:2211`. We can point application containers at another service\r\nlocation by changing the above NAT rule, without having to alter the\r\napplications themselves.\r\n\r\n### Service routing\r\n\r\nThe [service export](#service-export) and\r\n[service import](#service-import) features can be combined to\r\nestablish connectivity between applications and services residing on\r\ndisjoint networks, even when those networks are separated by firewalls\r\nand might have overlapping IP ranges. Each network imports its\r\nservices into weave, and in turn exports from weave services required\r\nby its applications. There are no application containers in this\r\nscenario (though of course there could be); weave is acting purely as\r\nan address translation and routing facility, using the weave\r\napplication network as an intermediary.\r\n\r\nIn our example above, the netcat service on $HOST3 is imported into\r\nweave via $HOST1. We can export it on $HOST2 by first exposing the\r\napplication network with\r\n\r\n    host2# weave expose 10.0.1.102/24\r\n\r\nand then adding a NAT rule which routes traffic from the $HOST2\r\nnetwork (i.e. anything which can connect to $HOST2) to the service\r\nendpoint in the weave network\r\n\r\n    host2# iptables -t nat -A PREROUTING -p tcp -i eth0 --dport 4433 \\\r\n           -j DNAT --to-destination 10.0.1.101:3322\r\n\r\nNow any host on the same network as $HOST2 can access the service with\r\n\r\n    echo 'Hello, world.' | nc $HOST2 4433\r\n\r\nFurthermore, as explained in [service-binding](#service-binding), we\r\ncan dynamically alter the service locations without having to touch\r\nthe applications that access them, e.g. we could move the example\r\nnetcat service to $HOST4:2211 while retaining its 10.0.1.101:3322\r\nendpoint in the weave network.\r\n\r\n### Multi-cloud networking\r\n\r\nWeave can network containers hosted in different cloud providers /\r\ndata centres. So, for example, one could run an application consisting\r\nof containers on GCE, EC2 and in local data centres.\r\n\r\nTo enable this, the network must be configured to permit TCP and UDP\r\nconnections to port 6783 of the docker hosts.\r\n\r\n### Multi-hop routing\r\n\r\nA network of containers across more than two hosts can be established\r\neven when there is only partial connectivity between the hosts. Weave\r\nis able to route traffic between containers as long as there is at\r\nleast one *path* of connected hosts between them.\r\n\r\nSo, for example, if a docker host in a local data centre can connect\r\nto hosts in GCE and EC2, but the latter two cannot connect to each\r\nother, containers in the latter two can still communicate; weave will\r\nroute the traffic via the local data centre.\r\n\r\n### Dynamic topologies\r\n\r\nTo add a host to an existing weave network, one simply launches\r\nweave on the host, supplying the address of at least one existing\r\nhost. Weave will automatically discover the other hosts in the other\r\nnetwork and establish connections to them if it can (in order to avoid\r\nunnecessary multi-hop routing).\r\n\r\n### Container mobility\r\n\r\nContainers can be moved between hosts without requiring any\r\nreconfiguration or, in many cases, restarts of other containers. All\r\nthat is required is for the migrated container to be started with the\r\nsame IP address as it was given originally.\r\n\r\n### Fault tolerance\r\n\r\nWeave peers continually exchange topology information, and monitor\r\nand (re)establish network connections to other peers. So if hosts or\r\nnetworks fail, weave can \"route around\" the problem. This includes\r\nnetwork partitions; containers on either side of a partition can\r\ncontinue to communicate, with full connectivity being restored when\r\nthe partition heals.\r\n\r\nThe weave container is very light-weight - just over 8MB image size\r\nand a few 10s of MBs of runtime memory - and disposable. I.e. should\r\nweave ever run into difficulty, one can simply stop it (with `weave\r\nstop`) and restart it. Application containers do *not* have to be\r\nrestarted in that event, and indeed may not even experience a\r\ntemporary connectivity failure if the weave container is restarted\r\nquickly enough.\r\n\r\n## Troubleshooting\r\n\r\nMake sure you are running the latest version - you can download it\r\nwith\r\n\r\n    docker pull zettio/weave\r\n\r\nCheck the weave container logs with\r\n\r\n    docker logs weave\r\n\r\nA reasonable amount of information, and all errors, get logged there.\r\n\r\nThe log verbosity can be increased by supplying the `-debug` flag when\r\nlaunching weave. Be warned, this will log information on a per-packet\r\nbasis, so can produce a lot of output.\r\n\r\nOne can ask a weave router to report its status with\r\n\r\n    weave status\r\n\r\nTo stop weave, run\r\n\r\n    weave stop\r\n\r\nNote that this leaves the local application container network intact;\r\ncontainers on the local host can continue to communicate, whereas\r\ncommunication with containers on different hosts, as well as service\r\nexport/import, is disrupted but resumes when weave is relaunched.\r\n\r\nTo stop weave and completely remove all traces of the weave network on\r\nthe local host, run\r\n\r\n    weave reset\r\n\r\nAny running application containers will permanently lose connectivity\r\nwith the weave network and have to be restarted in order to\r\nre-connect.\r\n\r\n### Reboots\r\n\r\nWhen a host reboots, docker's default behaviour is to restart any\r\ncontainers that were running. Since weave relies on special network\r\nconfiguration outside of the containers, the weave network will not\r\nfunction in this state.\r\n\r\nTo remedy this, stop and re-launch the weave container, and re-attach\r\nthe application containers with `weave attach`.\r\n\r\nFor a more permanent solution,\r\n[disable Docker's auto-restart feature](https://docs.docker.com/articles/host_integration/)\r\nand create appropriate startup scripts to launch weave and run\r\napplication containers from your favourite process manager.\r\n\r\n## Installation with Boot2Docker\r\n\r\nIf you are running Docker inside the Boot2Docker VM, e.g. because you\r\nare on a Mac, then the following changes are required to these\r\ninstructions:\r\n\r\nAssuming you have fetched the 'weave' script via curl or similar, and\r\nit is in the current directory, transfer it to the Boot2Docker VM and\r\nmake it executable like this:\r\n\r\n    host1$ boot2docker ssh \"cat > weave\" < weave\r\n    host1$ boot2docker ssh \"chmod a+x weave\"\r\n\r\nThen, if we were trying to create the same containers as in the first\r\nexample above, the 'launch' command would be run like this:\r\n\r\n    host1$ boot2docker ssh \"sudo ./weave launch 10.0.0.1/16\"\r\n\r\nand the 'run' command like this:\r\n\r\n    host1# C=$(boot2docker ssh \"sudo ./weave run 10.0.1.1/24 -t -i ubuntu\")\r\n\r\n## Building\r\n\r\n(NB. This is only necessary if you want to work on weave. Also, these\r\ninstructions have only been tested on Ubuntu.)\r\n\r\nTo build weave you need `libpcap-dev` and `docker` installed. And `go`\r\n(and `git` and `hg` to fetch dependencies).\r\n\r\nThe package name is `github.com/zettio/weave`, so assuming `$GOPATH`\r\nis set:\r\n\r\n    $ cd $GOPATH\r\n    $ WEAVE=github.com/zettio/weave\r\n    $ git clone https://$WEAVE src/$WEAVE\r\n    $ cd src/$WEAVE\r\n\r\nThen simply run\r\n\r\n    $ make -C weaver\r\n\r\nThis will build the weave router, produce a docker image\r\n`zettio/weave` and export that image to /tmp/weave.tar\r\n\r\n## How does it work?\r\n\r\nWeave creates a network bridge on the host. Each container is\r\nconnected to that bridge via a veth pair, the container side of which\r\nis given the IP address & netmask supplied in 'weave run'. Also\r\nconnected to the bridge is the weave router container, which is given\r\nthe IP address & netmask supplied in 'weave launch'.\r\n\r\nA weave router captures Ethernet packets from its bridge-connected\r\ninterface in promiscuous mode, using 'pcap'. This typically excludes\r\ntraffic between local containers, and between the host and local\r\ncontainers, all of which is routed straight over the bridge by the\r\nkernel. Captured packets are forwarded over UDP to weave router peers\r\nrunning on other hosts. On receipt of such a packet, a router injects\r\nthe packet on its bridge interface using 'pcap' and/or forwards the\r\npacket to peers.\r\n\r\nWeave routers learn which peer host a particular MAC address resides\r\non. They combine this knowledge with topology information in order to\r\nmake routing decisions and thus avoid forwarding every packet to every\r\npeer. The topology information captures which peers are connected to\r\nwhich other peers; weave can route packets in partially connected\r\nnetworks with changing topology.\r\n\r\nWeave routers establish TCP connections to each other, over which they\r\nperform a protocol handshake and subsequently exchange topology\r\ninformation. These connections are encrypted if so configured. Peers\r\nalso establish UDP \"connections\", possibly encrypted, for the\r\naforementioned packet forwarding. These \"connections\" are duplex and\r\ncan traverse firewalls.\r\n\r\nMore details on the inner workings of weave can be found in the\r\n[architecture documentation](docs/architecture.txt).\r\n\r\n## Contact Us\r\n\r\nFound a bug, want to suggest a feature, or have a question?\r\n[File an issue](https://github.com/zettio/weave/issues), or email\r\nweave@zett.io. When reporting a bug, please include which version of\r\nweave you are running, as shown by `weave version`.\r\n\r\nFollow weave on Twitter:\r\n[@weavenetwork](https://twitter.com/weavenetwork).\r\n\r\nRead the Weave blog:\r\n[Weaveblog](http://weaveblog.com/).\r\n\r\nDiscuss weave on\r\n[Hacker News](https://news.ycombinator.com/item?id=8289786).\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}